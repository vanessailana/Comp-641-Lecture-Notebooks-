{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e392c49",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558d1da4",
   "metadata": {},
   "source": [
    "Trust but Verify:\n",
    "Cross-Validation, Metric Selection, and Class Imbalance\n",
    "\n",
    "Learning Objectives\n",
    "• Apply cross-validation (KFold, StratifiedKFold)\n",
    "• Run basic hyperparameter search\n",
    "• Choose metrics that match the task and class balance (ROC-AUC, PR-AUC, F1, MCC)\n",
    "• Detect and prevent data leakage\n",
    "• Handle imbalance with class weights, resampling, and threshold tuning\n",
    "• Document seeds, splits, and pipelines for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c69be0",
   "metadata": {},
   "source": [
    "Why “Trust but Verify”?\n",
    "• Models can look strong for the wrong reasons\n",
    "• Evaluation is easy to accidentally “cheat”\n",
    "• A single bad choice can inflate results by 10–50 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc99415",
   "metadata": {},
   "source": [
    "Accuracy can be misleading\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "When classes are imbalanced:\n",
    "• Predicting “all negative” can look “accurate”\n",
    "• The model can be useless for the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e8dcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.95)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 95 negatives, 5 positives\n",
    "y_true = np.array([0]*95 + [1]*5)\n",
    "\n",
    "# model predicts all zeros\n",
    "y_pred = np.zeros_like(y_true)\n",
    "\n",
    "acc = (y_true == y_pred).mean()\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ce7ad",
   "metadata": {},
   "source": [
    "Confusion Matrix (binary classification)\n",
    "\n",
    "                Pred 0      Pred 1\n",
    "Actual 0           TN         FP\n",
    "Actual 1           FN         TP\n",
    "\n",
    "Key idea:\n",
    "• Errors come in two types: false positives and false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a2b77",
   "metadata": {},
   "source": [
    "Core classification metrics\n",
    "Precision = TP / (TP + FP)\n",
    "Recall    = TP / (TP + FN)\n",
    "F1        = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "Interpretation\n",
    "• Precision: “When I predict positive, how often am I right?”\n",
    "• Recall:    “Of all real positives, how many did I catch?”\n",
    "• F1:        balance of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f78e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vanessaklotzman/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision_score(y_true, y_pred), recall_score(y_true, y_pred), f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12757522",
   "metadata": {},
   "source": [
    "ROC-AUC (Receiver Operating Characteristic)\n",
    "• Uses predicted scores, not just hard labels\n",
    "• Varies the classification threshold\n",
    "• Plots:\n",
    "  TPR (Recall) vs FPR\n",
    "\n",
    "AUC meaning:\n",
    "• Probability the model ranks a random positive above a random negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e9340",
   "metadata": {},
   "source": [
    "Precision–Recall (PR) curve\n",
    "• Focuses on the positive class\n",
    "• Better diagnostic when positives are rare\n",
    "\n",
    "PR-AUC meaning:\n",
    "• Average precision across recall levels\n",
    "• Sensitive to false positives when positives are rare\n",
    "\n",
    "Rule of thumb:\n",
    "• If the positive class is rare → consider PR-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb5d1b",
   "metadata": {},
   "source": [
    "MCC (Matthews Correlation Coefficient)\n",
    "• Uses all four confusion matrix cells\n",
    "• Works well with imbalance\n",
    "• Range: -1 to +1\n",
    "  +1 perfect, 0 random, -1 perfectly wrong\n",
    "\n",
    "MCC formula:\n",
    "(TP*TN - FP*FN) / sqrt((TP+FP)(TP+FN)(TN+FP)(TN+FN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d5292",
   "metadata": {},
   "source": [
    "Choosing the right metric\n",
    "Ask:\n",
    "• What type of error is worse? FP or FN?\n",
    "• Are classes imbalanced?\n",
    "• Do we need calibrated probabilities or just ranking?\n",
    "• Do we care about performance at a specific threshold?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40272f52",
   "metadata": {},
   "source": [
    "Why cross-validation (CV)?\n",
    "A single train/test split:\n",
    "• depends on the random seed\n",
    "• can be unusually easy or hard\n",
    "• gives a high-variance estimate\n",
    "\n",
    "Cross-validation:\n",
    "• repeats evaluation across multiple splits\n",
    "• reduces variance\n",
    "• produces a more reliable estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ff7f5",
   "metadata": {},
   "source": [
    "K-Fold Cross-Validation\n",
    "1) Split data into K folds\n",
    "2) For each fold:\n",
    "   • train on K-1 folds\n",
    "   • validate on the remaining fold\n",
    "3) Average the scores\n",
    "\n",
    "Benefits:\n",
    "• Uses data efficiently\n",
    "• Reduces dependence on one split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70386b5f",
   "metadata": {},
   "source": [
    "StratifiedKFold (classification)\n",
    "Goal:\n",
    "• preserve class proportions in each fold\n",
    "\n",
    "Why it matters:\n",
    "• avoids folds with “almost no positives”\n",
    "• makes metrics comparable across folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b121f0f",
   "metadata": {},
   "source": [
    "What does CV estimate?\n",
    "• An estimate of generalization performance\n",
    "• Under the assumption data is i.i.d. (independent and identically distributed)\n",
    "\n",
    "CV does NOT fix:\n",
    "• data leakage\n",
    "• dataset shift\n",
    "• bad features\n",
    "• label noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287342c",
   "metadata": {},
   "source": [
    "Data leakage = using information in training that would not be available at prediction time\n",
    "\n",
    "Common leakage sources:\n",
    "• fitting preprocessing on all data before splitting\n",
    "• target leakage features (post-outcome variables)\n",
    "• duplicates across train and test\n",
    "• time leakage (future information in the past)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed779c8",
   "metadata": {},
   "source": [
    " LEAGKAGE DEMO: scaling before CV\n",
    "\n",
    "Wrong approach:\n",
    "• scale on full dataset\n",
    "• then do cross-validation\n",
    "\n",
    "Right approach:\n",
    "• use Pipeline so scaling happens inside each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "991167ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0), np.float64(0.0))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=2000, n_features=20, n_informative=5,\n",
    "    weights=[0.95, 0.05], random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# WRONG: scaling on full data before CV\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # leakage\n",
    "wrong_scores = cross_val_score(LogisticRegression(max_iter=1000), X_scaled, y, cv=cv, scoring=\"f1\")\n",
    "\n",
    "# RIGHT: pipeline scales inside each fold\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "right_scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"f1\")\n",
    "\n",
    "wrong_scores.mean(), right_scores.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84240ec5",
   "metadata": {},
   "source": [
    "Reproducibility checklist\n",
    "• Set random_state seeds\n",
    "• Record split strategy (KFold vs StratifiedKFold)\n",
    "• Use Pipelines for preprocessing + model\n",
    "• Report mean ± std across folds\n",
    "• Keep a final untouched test set (optional but recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6399631",
   "metadata": {},
   "source": [
    "Hyperparameter search\n",
    "Goal:\n",
    "• choose model settings using ONLY training data\n",
    "\n",
    "Two common methods:\n",
    "• GridSearchCV: tries every combination\n",
    "• RandomizedSearchCV: samples combinations\n",
    "\n",
    "Important:\n",
    "• the search itself must be inside CV\n",
    "• do NOT tune on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d485aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "    \"clf__penalty\": [\"l2\"],\n",
    "    \"clf__solver\": [\"lbfgs\"]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "search.best_params_, search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe883f",
   "metadata": {},
   "source": [
    "Class imbalance changes:\n",
    "• metrics (accuracy becomes less useful)\n",
    "• training (the model may ignore the minority class)\n",
    "• decision threshold (0.5 may be wrong)\n",
    "\n",
    "Three simple fixes:\n",
    "• class weights\n",
    "• resampling (over/under-sampling)\n",
    "• threshold tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104163c2",
   "metadata": {},
   "source": [
    "Fix #1: class weights\n",
    "Idea:\n",
    "• penalize mistakes on minority class more heavily\n",
    "Common:\n",
    "• class_weight=\"balanced\" (scikit-learn)\n",
    "\n",
    "Use when:\n",
    "• you want a simple, low-risk improvement\n",
    "• you do not want to change the dataset size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0826c355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'f1': np.float64(0.0),\n",
       "  'roc_auc': np.float64(0.782779738584488),\n",
       "  'average_precision': np.float64(0.18361580994336668)},\n",
       " {'f1': np.float64(0.24312387390733486),\n",
       "  'roc_auc': np.float64(0.7979325863230876),\n",
       "  'average_precision': np.float64(0.1504554393162627)})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pipe_unweighted = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "pipe_weighted = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "scoring = {\"f1\": \"f1\", \"roc_auc\": \"roc_auc\", \"average_precision\": \"average_precision\"}\n",
    "\n",
    "res1 = cross_validate(pipe_unweighted, X, y, cv=cv, scoring=scoring)\n",
    "res2 = cross_validate(pipe_weighted, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "{m: res1[\"test_\"+m].mean() for m in scoring}, {m: res2[\"test_\"+m].mean() for m in scoring}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df96bcae",
   "metadata": {},
   "source": [
    "Fix #2: resampling\n",
    "• Oversampling: duplicate or synthesize minority examples\n",
    "• Undersampling: drop majority examples\n",
    "\n",
    "Pros:\n",
    "• can help models learn minority patterns\n",
    "\n",
    "Cons:\n",
    "• risk of overfitting (oversampling)\n",
    "• loss of information (undersampling)\n",
    "\n",
    "Important:\n",
    "• resampling must happen inside CV folds (Pipeline!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e2757",
   "metadata": {},
   "source": [
    "Fix #3: decision-threshold tuning\n",
    "Default threshold = 0.5 is not sacred\n",
    "\n",
    "Workflow:\n",
    "1) Train a model that outputs probabilities or scores\n",
    "2) Choose a threshold based on a metric or constraint\n",
    "   • maximize F1\n",
    "   • target recall ≥ 0.90\n",
    "   • control false positive rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a623fb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.636406148017043),\n",
       " np.float64(0.30645161290293393),\n",
       " np.float64(0.18627450980392157),\n",
       " np.float64(0.8636363636363636))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "pipe.fit(X_tr, y_tr)\n",
    "probs = pipe.predict_proba(X_te)[:, 1]\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_te, probs)\n",
    "\n",
    "f1 = 2 * prec * rec / (prec + rec + 1e-12)\n",
    "best_idx = np.argmax(f1)\n",
    "best_threshold = thr[max(best_idx-1, 0)]  # thr is length-1 vs prec/rec\n",
    "\n",
    "best_threshold, f1[best_idx], prec[best_idx], rec[best_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc53665",
   "metadata": {},
   "source": [
    "Important: avoid “double dipping”\n",
    "• If you tune thresholds or hyperparameters,\n",
    "  do it using CV or a validation split\n",
    "• Keep the final test set untouched until the end\n",
    "\n",
    "\n",
    "Best practice:\n",
    "• Nested CV for research-grade estimates\n",
    "• Simple CV + final test set for most projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1dc1a",
   "metadata": {},
   "source": [
    "Nested Cross-Validation (concept)\n",
    "Outer loop:\n",
    "• estimates generalization\n",
    "Inner loop:\n",
    "• chooses hyperparameters\n",
    "\n",
    "Why it matters:\n",
    "• prevents over-optimistic tuning results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2607fe1",
   "metadata": {},
   "source": [
    "Reliable evaluation workflow\n",
    "1) Define the metric(s) that match your task\n",
    "2) Build a Pipeline (preprocessing + model)\n",
    "3) Use StratifiedKFold for imbalanced classification\n",
    "4) Run CV to estimate baseline performance\n",
    "5) Tune hyperparameters with GridSearchCV / RandomizedSearchCV\n",
    "6) (Optional) Tune threshold on validation\n",
    "7) Report mean ± std across folds, then final test score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26022c",
   "metadata": {},
   "source": [
    " Accuracy can hide failure under imbalance\n",
    "• Choose metrics based on consequences\n",
    "• Use StratifiedKFold + Pipelines to avoid leakage\n",
    "• Tune hyperparameters inside CV\n",
    "• Handle imbalance: weights, resampling, threshold tuning\n",
    "• Document everything so results are reproducible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f275a0",
   "metadata": {},
   "source": [
    "If positives are 1% of the data, which is usually more informative:\n",
    "ROC-AUC or PR-AUC? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da3f98",
   "metadata": {},
   "source": [
    "Cheat sheet\n",
    "• Imbalanced classification: StratifiedKFold + PR-AUC / F1 / MCC\n",
    "• Use Pipeline for preprocessing to prevent leakage\n",
    "• Tune hyperparameters with GridSearchCV inside CV\n",
    "• Consider class_weight=\"balanced\"\n",
    "• Tune threshold if recall/precision trade-off matters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
